---
# Leave the homepage title empty to use the site title
title: ""
date: 2022-10-24
type: landing

design:
  # Default section spacing
  spacing: "6rem"

sections:
  - block: resume-biography-3
    content:
      # Choose a user profile to display (a folder name within `content/authors/`)
      username: admin
      text: ""
      # Show a call-to-action button under your biography? (optional)
      button:
        text: Download CV
        url: uploads/resume.pdf
    design:
      css_class: dark
      background:
        color: black
        image:
          # Add your image background to `assets/media/`.
          filename: stacked-peaks.svg
          filters:
            brightness: 1.0
          size: cover
          position: center
          parallax: false
  - block: markdown
    content:
      title: 'ğŸ“š My Research'
      subtitle: ''
      text: |-
        Hi! I'm Shoichi Hasegawa.

        I'm interested in multimodal language understanding for domestic service robots.
        Currently, I'm conducting research on robots that support human life in the home, based on the framework of symbol emergence in robotics, by leveraging spatial semantic understanding technologies and large language models.
        I'm a doctoral student at Ritsumeikan University and am involved in the <a href="https://avatar-ss.org/en/index.html">ISHIGURO Project (Moonshot Goal 1)</a>ï¼Œ<a href="https://en.ritsumei.ac.jp/research/r-giro/project/fourth/sato/">R-GIRO (Symbol Emergence Systems Science)</a>ï¼Œ<a href="https://xtech.nikkei.com/atcl/nxt/mag/rob/18/00003/00123/">HSRT-X (Matsuo Lab)</a>.
        My goal is to realize a domestic service robot that interacts with humans like a member of the familyâ€”much like "Doraemon."

        Keywords:

        Domestic service robot, multimodal language understanding, large language models, robotics foundation models, symbol emergence robotics

        é•·è°·å·ç¿”ä¸€ã¨ç”³ã—ã¾ã™ï¼

        ç§ã¯å®¶åº­ç”¨ã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒœãƒƒãƒˆã«ãŠã‘ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨€èªç†è§£ã«é–¢å¿ƒã‚’æŒã£ã¦ã„ã¾ã™ï¼
        ç¾åœ¨ã¯è¨˜å·å‰µç™ºãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã®æ çµ„ã¿ã«åŸºã¥ãã€ç©ºé–“ã®æ„å‘³ç†è§£æŠ€è¡“ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ãªãŒã‚‰ã€å®¶åº­å†…ã§äººé–“ã®ç”Ÿæ´»ã‚’æ”¯æ´ã™ã‚‹ãƒ­ãƒœãƒƒãƒˆã®ç ”ç©¶ã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ï¼
        ç«‹å‘½é¤¨å¤§å­¦ã®åšå£«èª²ç¨‹ã«åœ¨ç±ã—ã€<a href="https://avatar-ss.org/">çŸ³é»’æµ©ãƒ ãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ</a>ï¼Œ<a href="https://www.ritsumei.ac.jp/rgiro/project/fourth/sato/">R-GIRO (è¨˜å·å‰µç™ºã‚·ã‚¹ãƒ†ãƒ ç§‘å­¦å‰µæˆ)</a>ï¼Œ<a href="https://xtech.nikkei.com/atcl/nxt/mag/rob/18/00003/00123/">HSRT-X (æ±äº¬å¤§å­¦æ¾å°¾ç ”ä¸»å°)</a>ã«å‚ç”»ã—ã¦ã„ã¾ã™ï¼
        æœ€çµ‚çš„ã«ã¯ã€ã€Œå®¶æ—ã®ä¸€å“¡ã®ã‚ˆã†ã«äººã¨é–¢ã‚ã‚‹å®¶åº­ç”¨ã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒœãƒƒãƒˆï¼ˆãƒ‰ãƒ©ãˆã‚‚ã‚“ï¼‰ã€ã®å®Ÿç¾ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ï¼

        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:

        å®¶åº­ç”¨ã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒœãƒƒãƒˆï¼Œãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨€èªç†è§£ï¼Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼Œãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹åŸºç›¤ãƒ¢ãƒ‡ãƒ«ï¼Œè¨˜å·å‰µç™ºãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹

    design:
      columns: '1'
  - block: collection
    id: papers
    content:
      title: 'â­ Featured Publications'
      filters:
        folders:
          - publication
        featured_only: true
    design:
      view: article-grid
      columns: 2
  # - block: markdown
  #   id: publications
  #   content:
  #     title: 'ğŸ’ª Recent Publications'
  #     text: |
  #       1. <div style="font-size: 0.8em">é è—¤ç´”éŸ³, <u><strong>é•·è°·å·ç¿”ä¸€</strong></u>, ä¸­ç”°å‹è²´, æ‰å±±æ»‰å¹³, è°·å£å½°, ä¸Šå·å¤šæµå­, å®‰ç”°è£•å­, è°·å£å¿ å¤§ "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸè¤‡ç·šå¾„è·¯ç­‰è‡³æ€§ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã®å›³ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™º," <strong>ç¬¬4å›TEAã¨è³ªçš„æ¢ç©¶å­¦ä¼š</strong>, 2025, accepted. </div>
  #       1. <div style="font-size: 0.8em">L. El Hafi, K. Onishi, <u><strong>S. Hasegawa</strong></u>, A. Oyama, T. Ishikawa, M. Osada, C. Tornberg, R. Kado, K. Murata, S. Hashimoto, S. Carrera Villalobos, A. Taniguchi, GA. Garcia Ricardez, Y. Hagiwara, T. Aoki, K. Iwata, T. Horii, Y. Horikawa, T. Miyashita, T. Taniguchi, H. Ishiguro, "Public Evaluation on Potential Social Impacts of Fully Autonomous Cybernetic Avatars for Physical Support in Daily-Life Environments: Large-Scale Demonstration and Survey at Avatar Land," <strong>IEEE International Conference on Advanced Robotics and its Social Impacts (ARSO)</strong>, 2025, accepted. </div>
      # filters:
      #   folders:
      #     - publication
      #   exclude_featured: false
    # design:
    #   view: citation
  # - block: collection
  #   id: talks
  #   content:
  #     title: Recent & Upcoming Talks
  #     filters:
  #       folders:
  #         - event
  #   design:
  #     view: article-grid
  #     columns: 1
  - block: collection
    id: news
    content:
      title:  'ğŸš€ Recent News'
      subtitle: ''
      text: ''
      # Page type to display. E.g. post, talk, publication...
      page_type: post
      # Choose how many pages you would like to display (0 = all pages)
      count: 5
      # Filter on criteria
      filters:
        author: ""
        category: ""
        tag: ""
        exclude_featured: false
        exclude_future: false
        exclude_past: false
        publication_type: ""
      # Choose how many pages you would like to offset by
      offset: 0
      # Page order: descending (desc) or ascending (asc) date.
      order: desc
    design:
      # Choose a layout view
      view: date-title-summary
      # Reduce spacing
      spacing:
        padding: [0, 0, 0, 0]
    
  - block: markdown
    id: publications
    content:
      title: 'ğŸ“œ Representative Papers'
      subtitle: ''
      text: |
        Full Publications (Google Scholor and Researchmap) is here.

        ### Integration of Probabilistic Logic and Probabilistic Generative Models for Understanding Object Placements
        1. <div style="font-size: 0.8em"><u><strong>S. Hasegawa</strong></u>, A. Taniguchi, Y. Hagiwara, L. El Hafi, T. Taniguchi, "Integrating Probabilistic Logic and Multimodal Spatial Concepts for Efficient Robotic Object Search in Home Environments," <strong>SICE Journal of Control, Measurement, and System Integration (SICE JCMSI)</strong>, Vol. 16, No. 1, pp. 400-422, 2023, <a href="https://www.tandfonline.com/doi/full/10.1080/18824889.2023.2283954">paper</a>. DOI: 10.1080/18824889.2023.2283954 </div>


        ### Large Language Models-based Robot Action Planning
        1. <div style="font-size: 0.8em">è©åŸ è‰¯ä¿¡, é•·è°·å· ç¿”ä¸€, å¤§å±± ç‘›, è°·å£ å½°, ã‚¨ãƒ« ãƒãƒ•ã‚£ ãƒ­ãƒˆãƒ•ã‚£, è°·å£ å¿ å¤§, "ç¾å ´ç’°å¢ƒã§å­¦ç¿’ã—ãŸçŸ¥è­˜ã«åŸºã¥ãæ›–æ˜§ãªç™ºè©±ã‹ã‚‰ã®ç”Ÿæ´»ç‰©ç†æ”¯æ´ã‚¿ã‚¹ã‚¯," ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (RSJ), å¤§é˜ª, 2023å¹´9æœˆ. (ğŸ†<strong>HSRã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å„ªç§€è«–æ–‡è³</strong>, ğŸ†<strong>ç¬¬5å› å„ªç§€ç ”ç©¶ãƒ»æŠ€è¡“è³</strong>)</div>


        ### Large Language Models-based Multi-Robot Collaboration
        1. <div style="font-size: 0.8em"><u><strong>S. Hasegawa</strong></u>, K. Murata, T. Ishikawa, Y. Hagiwara, A. Taniguchi, L. El Hafi, G. Garcia, T. Taniguchi, "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è¤‡æ•°ãƒ­ãƒœãƒƒãƒˆã®çŸ¥è­˜çµ±åˆã¨ã‚¿ã‚¹ã‚¯å‰²å½“ã‚’ç”¨ã„ãŸç¾å ´å­¦ç¿’ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›," <strong>Journal of RSJ Letter</strong>, 2024, accepted. </div>


        ### Robotics Foundation Models
        1. <div style="font-size: 0.8em">æ¾å¶‹ é”ä¹Ÿ, é«˜æ³¢ äº®ä»‹, ç¥åŸ å…ƒå°±, é‡å£ è£•è²´, æœ‰é¦¬ ç´”å¹³, æ± ç”° æ‚ ä¹Ÿ, æŸ³ç”° æ å¾, å²©ç”° å¥è¼”, é•·è°·å· ç¿”ä¸€, ã‚¨ãƒ« ãƒãƒ•ã‚£ ãƒ­ãƒˆãƒ•ã‚£, å±±å°¾ æ™ƒä¸–, ç£¯æœ¬ èˆªä¸–, å±±å£ ç›´ç´€, å°æ— é¼å¹³, æŸ´ æ™ºä¹Ÿ, çŸ¢é‡ å„ªé›…, æ°´è°· å½°ä¼¸, ç”°å‘ æ¨©, å €äº• éš†æ–—, æ‰æµ¦ å­”æ˜, è°·å£ å¿ å¤§, æ¾å°¾ è±Š, å²©æ¾¤ æœ‰ç¥, "HSRT-X: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’æ´»ç”¨ã—ãŸãƒ­ãƒœãƒƒãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰," ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (RSJ), å¤§é˜ª, 2024å¹´9æœˆ.</div>


        ### Exophora Resolution
        1. <div style="font-size: 0.8em">A. Oyama, S. Hasegawa, H. Nakagawa, A. Taniguchi, Y. Hagiwara, T. Taniguchi, "Exophora Resolution of Linguistic Instructions with a Demonstrative based on Real-World Multimodal Information," <strong>IEEE International Conference on Robot & Human Interactive Communication (RO-MAN)</strong>, pp. 2617-2623, Korea, Aug. 2023, <a href="https://ieeexplore.ieee.org/document/10309487">paper</a>. DOI: 10.1109/RO-MAN57019.2023.10309487 (ğŸ†<strong>ãƒ­ãƒœã‚«ãƒƒãƒ—ç ”ç©¶è³</strong>) </div>
        1. <div style="font-size: 0.8em">H. Nakagawa, S. Hasegawa, Y. Hagiwara, A. Taniguchi, T. Taniguchi, "Pointing Frame Estimation with Audio-Visual Time Series Data for Daily Life Service Robots," <strong>IEEE International Conference on Systems, Man, and Cybernetics (SMC)</strong>, Malaysia, Oct. 2024, in press, <a href="https://emergentsystemlabstudent.github.io/PointingImgEst/">project page</a>, <a href="https://speakerdeck.com/shoichi_hasegawa/pointing-frame-estimation-with-audio-visual-time-series-data-for-daily-life-service-robots">slide</a>. (ğŸ†<strong>Best Paper Award</strong>)</div>


        ### Instance Specific Image-Goal Navigation with Self-Supervised Learning
        1. <div style="font-size: 0.8em">T. Sakaguchi, A. Taniguchi*, Y. Hagiwara, L. El Hafi, S. Hasegawa, T. Taniguchi, "Object Instance Retrieval in Assistive Robotics: Leveraging Fine-Tuned SimSiam with Multi-View Images Based on 3D Semantic Map," <strong>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</strong>, Abu Dabi, Oct. 2024, in press, <a href="https://arxiv.org/abs/2404.09647">arxiv</a>, <a href="https://emergentsystemlabstudent.github.io/MultiViewRetrieve/">project page</a>, <a href="https://github.com/EmergentSystemLabStudent/MultiViewRetrieve">code</a>. </div>
        
        
        ### Foundation Models for Human-Robot Interaction
        1. <div style="font-size: 0.8em">E. Martin, <u><strong>S. Hasegawa</strong></u>, J. Solis, B. Macq, R. Ronsse, G A. Garcia Ricardez, L. El Hafi, T. Taniguchi, "Integrating Multimodal Communication and Comprehension Evaluation during Human-Robot Collaboration for Increased Reliability of Foundation Model-based Task Planning Systems," <strong>IEEE/SICE International Symposium on System Integration (SII)</strong>, Germany, Jan. 2025, accepted. </div>
        1. <div style="font-size: 0.8em">B. Bastin, S. Hasegawa, J. Solis, R. Ronsse, B. Macq, L. El Hafi, G A. Garcia Ricardez, T. Taniguchi, "GPTAlly: A Safety-Oriented System for Human-Robot Collaboration based on Foundation Models," <strong>IEEE/SICE International Symposium on System Integration (SII)</strong>, Germany, Jan. 2025, accepted. </div>

        <a href="./slides/#domestic" style="color: #4B65E2;">See All Slides ></a>
    design:
      columns: '1'
      spacing:
        # Customize the section spacing. Order is top, right, bottom, left.
        padding: ['80px', '0px', '20px', '0px']
  # - block: resume-awards
  #   id: awards
  #   content:
  #     title: ğŸ† Awards
  #     username: admin
  #   design:
  #     spacing:
  #       # Customize the section spacing. Order is top, right, bottom, left.
  #       padding: ['80px', '0px', '20px', '0px']
  - block: markdown
    id: experience
    content:
      title: 'Experience'
      subtitle: ''
      text: |
        ### ğŸ¢ Employments
        - <a href="">ç«‹å‘½é¤¨å¤§å­¦ç·åˆç§‘å­¦æŠ€è¡“ç ”ç©¶æ©Ÿæ§‹</a>, Shiga.
          - Research Assistant (Apr. 2023 - Present)
        - <a href="">ç«‹å‘½é¤¨å¤§å­¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿæ§‹</a>, Shiga.
          - Research Assistant (Apr. 2022 - Mar. 2023)
        - <a href="">OMRON Corporation</a>, Kyoto.
          - Research Internship (Feb. 2021 - Mar. 2021)
    
    design:
      columns: '1'
      spacing:
        # Customize the section spacing. Order is top, right, bottom, left.
        padding: ['80px', '0px', '20px', '0px']

  - block: markdown
    id: fellowships
    content:
      title: 'ğŸ“ Fellowships & Scholarships'
      subtitle: ''
      text: |
        ### Fellowships
        1. <div style="font-size: 0.8em"><a href="">ç«‹å‘½é¤¨å…ˆé€²ç ”ç©¶ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼å­¦ç”Ÿãƒ•ã‚§ãƒ­ãƒ¼ã‚·ãƒƒãƒ—ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆRARAÃ—SPRINGï¼‰(å›½ç«‹ç ”ç©¶é–‹ç™ºæ³•äººç§‘å­¦æŠ€è¡“æŒ¯èˆˆæ©Ÿæ§‹(JST) æ¬¡ä¸–ä»£ç ”ç©¶è€…æŒ‘æˆ¦çš„ç ”ç©¶ãƒ—ãƒ­ã‚°ãƒ©ãƒ )</a>, <strong>JPY 180K/month</strong>, Apr. 2024 - Mar. 2025.</div>
        1. <div style="font-size: 0.8em"><a href="">ç«‹å‘½é¤¨å¤§å­¦NEXTãƒ•ã‚§ãƒ­ãƒ¼ã‚·ãƒƒãƒ—ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ  (æ–‡éƒ¨ç§‘å­¦çœ ç§‘å­¦æŠ€è¡“ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‰µå‡ºã«å‘ã‘ãŸå¤§å­¦ãƒ•ã‚§ãƒ­ãƒ¼ã‚·ãƒƒãƒ—å‰µè¨­äº‹æ¥­)</a>, <strong>JPY 180K/month</strong>, Apr. 2022 - Mar. 2024.</div>

        ### Scholarships
        1. <div style="font-size: 0.8em"><a href="https://www.ritsumei.ac.jp/ru_gr/g-career/fellow/doctor/article.html/?id=2">ç«‹å‘½é¤¨å¤§å­¦å¤§å­¦é™¢ åšå£«èª²ç¨‹å¾ŒæœŸèª²ç¨‹ç ”ç©¶å¥¨åŠ±å¥¨å­¦é‡‘B</a>, <strong>JPY 250K</strong>, Jul. 2024.</div>
        1. <div style="font-size: 0.8em"><a href="https://www.ritsumei.ac.jp/ru_gr/g-career/fellow/master/article.html/?id=48">2å¹´æ¬¡å¯¾è±¡æˆç¸¾å„ªç§€è€…å¥¨å­¦é‡‘</a>, <strong>JPY 450K</strong>, May. 2021.</div>
        1. <div style="font-size: 0.8em"><a href="https://www.ritsumei.ac.jp/ru_gr/g-career/fellow/master/article.html/?id=50">1å¹´æ¬¡å¯¾è±¡æˆç¸¾å„ªç§€è€…å¥¨å­¦é‡‘</a>, <strong>JPY 450K</strong>, May. 2020.</div>
        1. <div style="font-size: 0.8em"><a href="https://www.ritsumei.ac.jp/scholarship/curriculum/#curriculum01">2018å¹´åº¦ç§‹å­¦æœŸ è¥¿åœ’å¯ºè¨˜å¿µå¥¨å­¦é‡‘ (æˆç¸¾å„ªç§€è€…æ )</a>, <strong>JPY 300K</strong>, Oct. 2018.</div>
        1. <div style="font-size: 0.8em"><a href="https://www.ritsumei.ac.jp/scholarship/curriculum/#curriculum01">2016å¹´åº¦ è¥¿åœ’å¯ºè¨˜å¿µå¥¨å­¦é‡‘ï¼ˆæˆç¸¾å„ªç§€è€…æ )</a>, <strong>JPY 300K</strong>, Apr. 2017.</div>
    design:
      columns: '1'
      # background:
      #   color: 'gray'
      # TODO:
      spacing:
        # Customize the section spacing. Order is top, right, bottom, left.
        padding: ['80px', '0px', '20px', '0px']
  - block: resume-skills
    id: skills
    content:
      title: ğŸ’» Skills & Certifications
      username: admin
    design:
      show_skill_percentage: false
      spacing:
        # Customize the section spacing. Order is top, right, bottom, left.
        padding: ['80px', '0px', '40px', '0px']
  - block: resume-languages
    content:
      title: ğŸ’¬ Languages
      username: admin
    design:
      spacing:
        # Customize the section spacing. Order is top, right, bottom, left.
        padding: ['10px', '0px', '20px', '0px']
  # - block: markdown
  #   content:
  #     title: 'ğŸ“° Misc'
  #     subtitle: ''
  #     text: |
  #       - <div style="font-size: 0.8em">é•·è°·å· ç¿”ä¸€, ç‰§åŸ æ˜‚å¿—, ãƒ‘ãƒ‰ãƒãƒŠãƒãƒ³ ã‚·ãƒƒãƒ€ãƒ¼ãƒˆ, è‹¥æ— å‹‡å¤ª, "å­¦ç”Ÿç·¨é›†å§”å“¡ä¼šå–æä¼ç”»ï¼šäººãŒ"ã“ã“ã‚''ã‚’æ„Ÿã˜ã‚‹æ°—ã®åˆ©ã„ãŸãƒ­ãƒœãƒƒãƒˆã®å®Ÿç¾ã‚’ç›®æŒ‡ã—ã¦,"æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ, vol.42, no.3, pp.247-252, 2024å¹´4æœˆ,ã€€<a href="https://www.jstage.jst.go.jp/article/jrsj/42/3/42_42_247/_article/-char/ja/">pdf</a>.</div>
  #       - <div style="font-size: 0.8em">é•·è°·å· ç¿”ä¸€, "ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼šãƒ¬ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ¼ã‚¬ãƒŠã‚¤ã‚ºãƒ‰ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼šåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ï¼ˆ2/3ï¼‰ï¼‰,"æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ, vol.42, no.1, pp.48-49, 2024å¹´1æœˆ,ã€€<a href="https://www.jstage.jst.go.jp/article/jrsj/42/1/42_42_48/_article/-char/ja/">pdf</a>.</div>
        
  #   design:
  #     columns: '1'
  #     spacing:
  #       # Customize the section spacing. Order is top, right, bottom, left.
  #       padding: ['80px', '0px', '40px', '0px']
---
#   - block: cta-card
#     demo: true # Only display this section in the Hugo Blox Builder demo site
#     content:
#       title: ğŸ‘‰ Build your own academic website like this
#       text: |-
#         This site is generated by Hugo Blox Builder - the FREE, Hugo-based open source website builder trusted by 250,000+ academics like you.

#         <a class="github-button" href="https://github.com/HugoBlox/hugo-blox-builder" data-color-scheme="no-preference: light; light: light; dark: dark;" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star HugoBlox/hugo-blox-builder on GitHub">Star</a>

#         Easily build anything with blocks - no-code required!
        
#         From landing pages, second brains, and courses to academic resumÃ©s, conferences, and tech blogs.
#       button:
#         text: Get Started
#         url: https://hugoblox.com/templates/
#     design:
#       card:
#         # Card background color (CSS class)
#         css_class: "bg-primary-700"
#         css_style: ""
# ---
